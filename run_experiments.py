import osimport subprocessimport toml# Base configuration for model.confMODEL_CONF_BASE = {    "TRAINING_PARAMETERS": {        "latent_dimension": 10,        "epochs": 30,  # Reduced for testing        "batch_size": 25,        "test_size": 100,        "real_synthetic_ratio": 5,        "synthetic_synthetic_ratio": 10,        "discriminator_learning_rate": 0.01,        "accuracy_threshold": 0.85,        "num_features": 9,    },    "WEIGHTS": {        "discriminator_loss_weight": 1,        "classifier_loss_weight": 1,        "sfd_loss_weight": 1,    },    "NAMES": {        "classifier_name": "classifier",    },    "MODELS": {        "directory": "models",        "exists": False,    },}# Paths for dataset and pretrained modelBASE_DIR = "/Users/Lerberber/Desktop/Bhat/SuperGans"DATASET_FILE = os.path.join(BASE_DIR, "sports_data_accelerometer.h5")PRETRAINED_MODEL = os.path.join(BASE_DIR, "LSTM_accelerometer.h5")OUTPUT_DIR = os.path.join(BASE_DIR, "results")STDOUT_DIR = os.path.join(BASE_DIR, "stdout")STDERR_DIR = os.path.join(BASE_DIR, "stderr")MODELS_DIR = os.path.join(BASE_DIR, "models")# Ensure output directories existos.makedirs(OUTPUT_DIR, exist_ok=True)os.makedirs(STDOUT_DIR, exist_ok=True)os.makedirs(STDERR_DIR, exist_ok=True)os.makedirs(MODELS_DIR, exist_ok=True)class Experiment:    def __init__(self, class_label):        self.class_label = class_label    def create_name_extension(self):        return f"accelerometer_class{self.class_label}C"    def write_model_conf(self, extension):        conf = MODEL_CONF_BASE.copy()        conf["MODELS"]["generator_filename"] = f"{MODELS_DIR}/G_{extension}.h5"        conf["MODELS"]["discriminator_filename"] = f"{MODELS_DIR}/D_{extension}.h5"        conf_path = os.path.join(OUTPUT_DIR, f"model_{extension}.conf")        with open(conf_path, "w") as f:            toml.dump(conf, f)        print(f"Model configuration saved to {conf_path}")        return conf_path    def write_toml_file(self, extension):        toml_data = {            "data_file_path": DATASET_FILE,            "classifier_path": PRETRAINED_MODEL,            "class_label": self.class_label,            "write_train_results": False,        }        toml_path = os.path.join(OUTPUT_DIR, f"{extension}.toml")        with open(toml_path, "w") as f:            toml.dump(toml_data, f)        print(f".toml configuration saved to {toml_path}")        return toml_path    def run_experiment(self):        extension = self.create_name_extension()        conf_path = self.write_model_conf(extension)        toml_path = self.write_toml_file(extension)        print(f"RUNNING EXPERIMENT: {extension}")        command = f"python3 main.py {toml_path} --save"        stdout_path = os.path.join(STDOUT_DIR, f"{extension}.txt")        stderr_path = os.path.join(STDERR_DIR, f"{extension}.txt")        with open(stdout_path, "w") as stdout_file, open(stderr_path, "w") as stderr_file:            process = subprocess.Popen(command, shell=True, stdout=stdout_file, stderr=stderr_file)            process.wait()        if process.returncode == 0:            print(f"Experiment {extension} completed successfully.")        else:            print(f"Experiment {extension} failed. Check {stderr_path} for details.")        os.remove(toml_path)        print(f"Removed temporary .toml file: {toml_path}")if __name__ == "__main__":    print("Starting experiments for all classes...")    for class_label in range(9):  # Iterate over all classes (0 to 8)        experiment = Experiment(class_label)        experiment.run_experiment()    print("All experiments completed.")